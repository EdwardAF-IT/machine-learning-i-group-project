{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Creating training and test sets\n",
    "import sklearn\n",
    "\n",
    "# File system management\n",
    "import os.path\n",
    "\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#training/test split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, ShuffleSplit\n",
    "\n",
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# here we can change some of the parameters interactively\n",
    "from ipywidgets import widgets as wd\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "#for weights standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Support vector machines\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 1,324,973 rows and 17 columns\n",
      "Wall time: 3.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Constants\n",
    "#DATAPATH_BASE = 'https://machinelearningi.blob.core.windows.net/group-project/'\n",
    "#DATAPATH_SAS_TOKEN = '?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-27T11:12:37Z&st=2020-01-23T04:12:37Z&spr=https&sig=jpIpjrp8dIg9eyUyPpmgTe5yj9i1ZoCSru5kBVHcUO8%3D'\n",
    "#DATAPATH_FILENAME = 'Arrest_Data_from_2010_to_Present.csv'\n",
    "#DATAPATH_SMALL_FILENAME = 'Arrest_Data_from_2010_to_Present_Small.csv'\n",
    "\n",
    "# Fully qualified paths ready to use\n",
    "#DATA_SOURCE = \"\".join([DATAPATH_BASE, DATAPATH_FILENAME, DATAPATH_SAS_TOKEN])\n",
    "\n",
    "# Options\n",
    "#pd.set_option('float_format', '{:.2f}'.format)  # Reign in the scientific notation for reasonable values\n",
    "\n",
    "# Load data for analysis; only read if needed because the import can take a long time\n",
    "#try:\n",
    "#    if len(df.index) < 1:\n",
    "#        df_raw = pd.read_csv(DATA_SOURCE) # If we get here, the dataframe was empty\n",
    "#except:   \n",
    "#    df_raw = pd.read_csv(DATA_SOURCE) # If we get here, the dataframe did not exist\n",
    "\n",
    "df_raw = pd.read_csv(\"Arrest_Data_From_2010_to_Present.csv\")\n",
    "\n",
    "df = df_raw\n",
    "\n",
    "print(\"The dataset has {:,} rows and {:,} columns\".format(*df.shape))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1277176 entries, 0 to 1324972\n",
      "Data columns (total 10 columns):\n",
      "Area ID               1277176 non-null object\n",
      "Reporting District    1277176 non-null object\n",
      "Age                   1277176 non-null int8\n",
      "Sex Code              1277176 non-null object\n",
      "Descent Code          1277176 non-null object\n",
      "Charge Group Code     1277176 non-null object\n",
      "Arrest Type Code      1277176 non-null object\n",
      "Hour                  1277176 non-null object\n",
      "arrest_month          1277176 non-null object\n",
      "arrest_day_of_week    1277176 non-null object\n",
      "dtypes: int8(1), object(9)\n",
      "memory usage: 98.7+ MB\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Time - filter out 0 and missing\n",
    "df = df[df['Time'] != 0]\n",
    "df['Time'] = df['Time'].astype(str) \n",
    "df = df[df['Time'] != 'nan']\n",
    "\n",
    "# Time - Convert float to string. Get rid of decimals. Replace missing or invalid values with '0000'.\n",
    "df['Time'] = df['Time'].astype(str).str.split(\".\", expand = True)[0].replace(to_replace = ['2400','nan'], value = '0000') \n",
    "\n",
    "# Time - Fill time column with leading zeros to have 4 characters total\n",
    "df['Time'] = df['Time'].apply(lambda x: '{0:0>4}'.format(x))\n",
    "\n",
    "# Time - Add colon to Time values by converting attribute to a datetime variable \n",
    "df['Time'] = pd.to_datetime(df['Time'], format = '%H%M').dt.time\n",
    "\n",
    "# Age - Drop the observations where Age is less than 16\n",
    "df.drop(df[df['Age'] < 16].index, inplace = True) \n",
    "\n",
    "# Arrest Type Code - Drop the observations where Arrest Type Code = 'D'\n",
    "df.drop(df[df['Arrest Type Code'] == 'D'].index, inplace = True) \n",
    "\n",
    "# Descent Code - Re-classify any descent not in (B,H,O,W) into 0\n",
    "descent_list = ['B','H','O','W']\n",
    "df['Descent Code'] = np.where(np.isin(df['Descent Code'],descent_list),df['Descent Code'],'O')\n",
    "\n",
    "# Get hour\n",
    "df['Hour'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "# Convert Arrest Date to datetime\n",
    "df['Arrest Date'] = pd.to_datetime(df['Arrest Date'])\n",
    "\n",
    "# Extract year, month, and day of week and add to dataframe as new attributes\n",
    "#df['arrest_year']= df['Arrest Date'].dt.year\n",
    "df['arrest_month']= df['Arrest Date'].dt.month\n",
    "df['arrest_day_of_week'] = df['Arrest Date'].dt.weekday_name\n",
    "\n",
    "# remove unecessary columns\n",
    "df.drop(['Cross Street','Charge Description','Charge','Charge Group Description','Time',\n",
    "         'Arrest Date','Report ID','Address','Area Name','Location'], axis=1, inplace=True)\n",
    "\n",
    "# Change data types\n",
    "df['Age'] = df['Age'].astype(np.int8)\n",
    "df['Reporting District'] = df['Reporting District'].astype(np.str)\n",
    "df['Area ID'] = df['Area ID'].astype(np.str)\n",
    "df['Charge Group Code'] = df['Charge Group Code'].astype(np.str)\n",
    "df['Hour'] = df['Hour'].astype(np.str)\n",
    "#df['arrest_year'] = df['arrest_year'].astype(np.str)\n",
    "df['arrest_month'] = df['arrest_month'].astype(np.str)\n",
    "df['arrest_day_of_week'] = df['arrest_day_of_week'].astype(np.str)\n",
    "\n",
    "df_lightgbm = df\n",
    "# print clean dataset\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create buckets for Age\n",
    "df['age_range'] = pd.cut(df.Age,[16,25,35,45,55,65,75,1e6],4,labels=[0,1,2,3,4,5,6]) # this creates a new variable\n",
    "df['age_range'] = df.age_range.astype(np.int)\n",
    "\n",
    "# Replace the current Sex atribute with something slightly more intuitive and readable\n",
    "df['IsMale'] = df['Sex Code']=='M' \n",
    "df.IsMale = df.IsMale.astype(np.int)\n",
    "\n",
    "# Perform one-hot encoding of the categorical data \"DOW\"\n",
    "tmp_df = pd.get_dummies(df['arrest_day_of_week'],prefix='DOW',drop_first=True)\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# Perform one-hot encoding of the categorical data \"Area ID\"\n",
    "tmp_df = pd.get_dummies(df['Area ID'],prefix='Area',drop_first=True)\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# Perform one-hot encoding of the categorical data \"Charge Group Code\"\n",
    "tmp_df = pd.get_dummies(df['Charge Group Code'],prefix='Charge',drop_first=True)\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# Perform one-hot encoding of the categorical data \"Hour\"\n",
    "tmp_df = pd.get_dummies(df['Hour'],prefix='Hour',drop_first=True)\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# Perform one-hot encoding of the categorical data \"Month\"\n",
    "tmp_df = pd.get_dummies(df['arrest_month'],prefix='Month',drop_first=True)\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1277176 entries, 0 to 1324972\n",
      "Data columns (total 94 columns):\n",
      "Arrest Type Code    1277176 non-null int64\n",
      "age_range           1277176 non-null int32\n",
      "IsMale              1277176 non-null int32\n",
      "DOW_Monday          1277176 non-null uint8\n",
      "DOW_Saturday        1277176 non-null uint8\n",
      "DOW_Sunday          1277176 non-null uint8\n",
      "DOW_Thursday        1277176 non-null uint8\n",
      "DOW_Tuesday         1277176 non-null uint8\n",
      "DOW_Wednesday       1277176 non-null uint8\n",
      "Area_10             1277176 non-null uint8\n",
      "Area_11             1277176 non-null uint8\n",
      "Area_12             1277176 non-null uint8\n",
      "Area_13             1277176 non-null uint8\n",
      "Area_14             1277176 non-null uint8\n",
      "Area_15             1277176 non-null uint8\n",
      "Area_16             1277176 non-null uint8\n",
      "Area_17             1277176 non-null uint8\n",
      "Area_18             1277176 non-null uint8\n",
      "Area_19             1277176 non-null uint8\n",
      "Area_2              1277176 non-null uint8\n",
      "Area_20             1277176 non-null uint8\n",
      "Area_21             1277176 non-null uint8\n",
      "Area_3              1277176 non-null uint8\n",
      "Area_4              1277176 non-null uint8\n",
      "Area_5              1277176 non-null uint8\n",
      "Area_6              1277176 non-null uint8\n",
      "Area_7              1277176 non-null uint8\n",
      "Area_8              1277176 non-null uint8\n",
      "Area_9              1277176 non-null uint8\n",
      "Charge_10.0         1277176 non-null uint8\n",
      "Charge_11.0         1277176 non-null uint8\n",
      "Charge_12.0         1277176 non-null uint8\n",
      "Charge_13.0         1277176 non-null uint8\n",
      "Charge_14.0         1277176 non-null uint8\n",
      "Charge_15.0         1277176 non-null uint8\n",
      "Charge_16.0         1277176 non-null uint8\n",
      "Charge_17.0         1277176 non-null uint8\n",
      "Charge_18.0         1277176 non-null uint8\n",
      "Charge_19.0         1277176 non-null uint8\n",
      "Charge_2.0          1277176 non-null uint8\n",
      "Charge_20.0         1277176 non-null uint8\n",
      "Charge_21.0         1277176 non-null uint8\n",
      "Charge_22.0         1277176 non-null uint8\n",
      "Charge_23.0         1277176 non-null uint8\n",
      "Charge_24.0         1277176 non-null uint8\n",
      "Charge_25.0         1277176 non-null uint8\n",
      "Charge_27.0         1277176 non-null uint8\n",
      "Charge_29.0         1277176 non-null uint8\n",
      "Charge_3.0          1277176 non-null uint8\n",
      "Charge_4.0          1277176 non-null uint8\n",
      "Charge_5.0          1277176 non-null uint8\n",
      "Charge_6.0          1277176 non-null uint8\n",
      "Charge_7.0          1277176 non-null uint8\n",
      "Charge_8.0          1277176 non-null uint8\n",
      "Charge_9.0          1277176 non-null uint8\n",
      "Charge_99.0         1277176 non-null uint8\n",
      "Charge_nan          1277176 non-null uint8\n",
      "Hour_1              1277176 non-null uint8\n",
      "Hour_10             1277176 non-null uint8\n",
      "Hour_11             1277176 non-null uint8\n",
      "Hour_12             1277176 non-null uint8\n",
      "Hour_13             1277176 non-null uint8\n",
      "Hour_14             1277176 non-null uint8\n",
      "Hour_15             1277176 non-null uint8\n",
      "Hour_16             1277176 non-null uint8\n",
      "Hour_17             1277176 non-null uint8\n",
      "Hour_18             1277176 non-null uint8\n",
      "Hour_19             1277176 non-null uint8\n",
      "Hour_2              1277176 non-null uint8\n",
      "Hour_20             1277176 non-null uint8\n",
      "Hour_21             1277176 non-null uint8\n",
      "Hour_22             1277176 non-null uint8\n",
      "Hour_23             1277176 non-null uint8\n",
      "Hour_3              1277176 non-null uint8\n",
      "Hour_4              1277176 non-null uint8\n",
      "Hour_5              1277176 non-null uint8\n",
      "Hour_6              1277176 non-null uint8\n",
      "Hour_7              1277176 non-null uint8\n",
      "Hour_8              1277176 non-null uint8\n",
      "Hour_9              1277176 non-null uint8\n",
      "Month_10            1277176 non-null uint8\n",
      "Month_11            1277176 non-null uint8\n",
      "Month_12            1277176 non-null uint8\n",
      "Month_2             1277176 non-null uint8\n",
      "Month_3             1277176 non-null uint8\n",
      "Month_4             1277176 non-null uint8\n",
      "Month_5             1277176 non-null uint8\n",
      "Month_6             1277176 non-null uint8\n",
      "Month_7             1277176 non-null uint8\n",
      "Month_8             1277176 non-null uint8\n",
      "Month_9             1277176 non-null uint8\n",
      "Descent_H           1277176 non-null uint8\n",
      "Descent_O           1277176 non-null uint8\n",
      "Descent_W           1277176 non-null uint8\n",
      "dtypes: int32(2), int64(1), uint8(91)\n",
      "memory usage: 140.1 MB\n",
      "Wall time: 2.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_arrest = df\n",
    "df_descent = df\n",
    "\n",
    "#Final encoding steps for Arrest Type Code classification dataset\n",
    "# Encode Arrest Type Code as Categorical\n",
    "cleanup_arrest = {\"Arrest Type Code\": {\"F\": 0, \"M\": 1, \"I\": 2, \"O\":3}}\n",
    "df_arrest.replace(cleanup_arrest,inplace=True)\n",
    "\n",
    "# Perform one-hot encoding of the categorical data \"Descent Code\"\n",
    "tmp_df = pd.get_dummies(df_arrest['Descent Code'],prefix='Descent',drop_first=True)\n",
    "df_arrest = pd.concat((df_arrest,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "df_arrest.drop(['Sex Code','Descent Code','arrest_day_of_week','Area ID','Reporting District','Charge Group Code',\n",
    "         'Age','Hour','arrest_month'], axis=1, inplace=True)\n",
    "\n",
    "df_arrest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search allows automated testing for things like KNN where you specify a grid of k values to test and record the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63859"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arrest_small = pd.DataFrame.sample(df_arrest, frac = .05, random_state = 34128)\n",
    "len(df_arrest_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#knn example\n",
    "#create parameter grid\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "X = df_arrest_small #data\n",
    "y = df_arrest_small['IsMale'] #target\n",
    "\n",
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors = k_range)\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv = 10, scoring = 'accuracy', return_train_score = False)\n",
    "\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on 1/10th% of the data, grid searchs says that 92% accuracy was achieved with k = 4 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(k_range, )\n",
    "score = pd.DataFrame(grid.cv_results_)['mean_test_score']\n",
    "plt.plot(k_range, score)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Mean Score Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn  = KNeighborsClassifier(n_neighbors = 4, weights = 'uniform')\n",
    "knn.fit(X, y)\n",
    "\n",
    "df_arrest_test = pd.DataFrame.sample(df_arrest, frac = .01, random_state = 3412)\n",
    "\n",
    "X = df_arrest_test #data\n",
    "y = df_arrest_test['IsMale'] #target\n",
    "\n",
    "#knn.predict(df_arrest_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple parameter grid search\n",
    "\n",
    "passes dict of possible variables to run function (knn), can add more? limited value depending on the type of analysis being performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi parameter grid search\n",
    "\n",
    "k_range = list(range(1, 31))\n",
    "weight_options = ['uniform', 'distance']\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid = GridSearchCV(knn, param_grid, cv = 10, scoring = 'accuracy', return_train_score = False)\n",
    "grid.fit(X, y)\n",
    "results = pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#score_dist = pd.DataFrame(grid.cv_results_)['mean_test_score']\n",
    "\n",
    "weight_u = pd.DataFrame(grid.cv_results_)[pd.DataFrame(grid.cv_results_)['param_weights'] == 'uniform']#results from uniform parameter weights\n",
    "weight_d = pd.DataFrame(grid.cv_results_)[pd.DataFrame(grid.cv_results_)['param_weights'] == 'distance']\n",
    "\n",
    "plt.plot(k_range, weight_u['mean_test_score'], color = 'orange')\n",
    "plt.plot(k_range, weight_d['mean_test_score'], color = 'blue')\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Mean Score Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "k_range = list(range(1, 31))\n",
    "weight_options = ['uniform', 'distance']\n",
    "\n",
    "param_dist = dict(n_neighbors = k_range, weights = weight_options)\n",
    "\n",
    "df_arrest_test = pd.DataFrame.sample(df_arrest, frac = .005, random_state = 3412)\n",
    "\n",
    "X = df_arrest_test #data\n",
    "y = df_arrest_test['IsMale'] #target\n",
    "\n",
    "\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5, return_train_score=False)\n",
    "rand.fit(X, y)\n",
    "\n",
    "pd.DataFrame(rand.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "k_range = list(range(1, 31))\n",
    "weight_options = ['uniform', 'distance']\n",
    "\n",
    "param_dist = dict(n_neighbors = k_range, weights = weight_options)\n",
    "\n",
    "df_arrest_test = pd.DataFrame.sample(df_arrest, frac = .05, random_state = 3412)\n",
    "\n",
    "X = df_arrest_test #data\n",
    "y = df_arrest_test['age_range'] #target\n",
    "\n",
    "\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5, return_train_score=False)\n",
    "rand.fit(X, y)\n",
    "\n",
    "pd.DataFrame(rand.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arrest_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test portion 2: fit arima model with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "    # prepare training dataset\n",
    "    train_size = int(len(X) * 0.66)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=arima_order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "    # calculate out of sample error\n",
    "    error = mean_squared_error(test, predictions)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "    dataset = dataset.astype('float32')\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    mse = evaluate_arima_model(dataset, order)\n",
    "                    if mse < best_score:\n",
    "                        best_score, best_cfg = mse, order\n",
    "                    print('ARIMA%s MSE=%.3f' % (order,mse))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#univariate data test, looking only at predicting... felonies over time?? arrests over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#dprep = {df_raw['Arrest Type Code'], }\n",
    "f_rate = pd.DataFrame()\n",
    "\n",
    "f_rate['Date'] = df_raw['Arrest Date']\n",
    "f_rate['Arrest Type'] = df_raw['Arrest Type Code']\n",
    "a_rate = f_rate.groupby('Date').count()\n",
    "\n",
    "plt.plot(a_rate, color = 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# evaluate parameters\n",
    "p_values = [0, 1, 2, 4, 6, 8, 10]\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(series.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a_rate_small = pd.DataFrame.sample(a_rate, frac = .2, random_state = 34128)\n",
    "len(a_rate_small)\n",
    "plt.plot(a_rate_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#gridsearch to search for time series model parameters #hmm 10min on .01% data, oh wait that's because \n",
    "#its only 39 occuranceshours on 10% data, \n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    " \n",
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "    # prepare training dataset\n",
    "    train_size = int(len(X) * 0.66)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=arima_order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "    # calculate out of sample error\n",
    "    error = mean_squared_error(test, predictions)\n",
    "    return error\n",
    " \n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "    dataset = dataset.astype('float32')\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    mse = evaluate_arima_model(dataset, order)\n",
    "                    if mse < best_score:\n",
    "                        best_score, best_cfg = mse, order\n",
    "                    print('ARIMA%s MSE=%.3f' % (order,mse))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))\n",
    " \n",
    "#load dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "series = a_rate_small\n",
    "# evaluate parameters\n",
    "p_values = [0, 1, 2, 4, 6, 8, 10]\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(series.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit arima model to ts and get predictions based on grid search results\n",
    "#ARIMA(0, 1, 1) MSE=10460.118 has the lowest MSE\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model = ARIMA(a_rate_small, order=(0, 1, 1))\n",
    "model_fit = model.fit(disp=0)\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.plot_predict(dynamic = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Deployment\n",
    "\n",
    "(5 points)\n",
    "\n",
    "How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\n",
    "\n",
    "Model deployment - although minority report style predictive modeling would be (cool), the amount of cleaning necessary to process the data would likely bottleneck the process for a single county, let alone large municipalities. An ideal use would be obtaining relevant retrospective analysis on things that could influence anything intersecting the data gathered during the arrests. Changes in demographic, criminal definition, (literally anything on a macro sociological scale if you abstract out far enough) can possibly be reflected in arrest data types. The ability to condense wide scale sociological change into easily understandable and verifiable conclusions would be the primary function of this type of retrospective analysis, although (other stuff) Conclusions like “The new highschool police mentorship program in this county has reduced arrests in high school age people by 15% ” or “This new spanish language program for officers has reduced hispanic misdemeanors by 10%” would be valuable information for citizens, politicians, and civil servants who have influence in the process of creating/implementing such civil programs.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison \n",
    "\n",
    "#### Task 1 - Classifying Arrest Type Code\n",
    "\n",
    "|Model| AUC | Precision | Recall | F1 Score | Support | \n",
    "| :-- | :-- | :-- | :-- | :-- | :-- |\n",
    "| \"model 1\" |     |     |     |     | \n",
    "| \"model 2\" |     |     |     |     |\n",
    "| \"model 3\" |     |     |     |     |\n",
    "\n",
    "#### Task 2 - Classifying Descent Code\n",
    "\n",
    "|Model| AUC | Precision | Recall | F1 Score | Support | \n",
    "| :-- | :-- | :-- | :-- | :-- | :-- |\n",
    "| \"model 1\" |     |     |     |     | \n",
    "| \"model 2\" |     |     |     |     |\n",
    "| \"model 3\" |     |     |     |     |\n",
    "\n",
    "(ROC/AUC) was chosen as the comparison metric for the 3 models on both tasks because (reasons go here). \n",
    "\n",
    "For classifying arrest code, the (winning model type) achieved a final ROC of (roc here),  (slightly/much) larger  compared to the others. This may be due to the unbalanced nature of the data; 60% misdemeanors, 30% felonies, less than 10% infractions and other.  This may fit the structural and computational assumptions of (winning model) better than (losing models). (evidence to back that up)\n",
    "\n",
    "For Classifying Descent Code, the (winning model type) had a final ROC of (ROC here), (much/ only marginally) better than (the other two, with (roc2, roc3)). Descent code was also a fairly unbalanced dataset, with almost 50% of the arrests recorded as Hispanic, 30% black, and 15% white. (winning model) operates on (assumptions of winning model) which are more closely reflected in the data than (the assumptions of the other models).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
