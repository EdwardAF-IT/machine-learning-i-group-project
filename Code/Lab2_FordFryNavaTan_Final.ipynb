{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Logistic Regression and Support Vector Machines\n",
    "MSDS 7331-407, Lab 2  \n",
    "*Jenna Ford, Edward Fry, Christian Nava, and Jonathan Tan* \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<a href='#Section_1'> 1. Preparation and Dataset Loading </a>  \n",
    "<a href='#Section_2'> 2. Data Cleansing (Lab 1) </a>  \n",
    "<a href='#Section_3'> 3. Create A Logistic Regression Model and a Support Vector Machine Model </a>  \n",
    "<a href='#Section_4'> 4. Model Advantages </a>  \n",
    "<a href='#Section_5'> 5. Weight Interpretation from Logistic Regression Model</a>  \n",
    "<a href='#Section_6'> 6. Insights from Support Vectors </a>  \n",
    "\n",
    "<!-- <a href='#Section_4_a'> &nbsp;&nbsp;&nbsp; a. Missing Values </a>  --> \n",
    "<!-- <a href='#Section_4_c_i'> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i. Cross Street </a>    --> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Section_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation and Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Creating training and test sets\n",
    "import sklearn\n",
    "\n",
    "# File system management\n",
    "import os.path\n",
    "\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATAPATH_BASE = 'https://machinelearningi.blob.core.windows.net/group-project/'\n",
    "DATAPATH_SAS_TOKEN = '?sv=2019-02-02&ss=bfqt&srt=sco&sp=rwdlacup&se=2020-04-27T11:12:37Z&st=2020-01-23T04:12:37Z&spr=https&sig=jpIpjrp8dIg9eyUyPpmgTe5yj9i1ZoCSru5kBVHcUO8%3D'\n",
    "DATAPATH_FILENAME = 'Arrest_Data_from_2010_to_Present.csv'\n",
    "\n",
    "# Fully qualified paths ready to use\n",
    "DATA_SOURCE = \"\".join([DATAPATH_BASE, DATAPATH_FILENAME, DATAPATH_SAS_TOKEN])\n",
    "\n",
    "# Options\n",
    "pd.set_option('float_format', '{:.2f}'.format)  # Reign in the scientific notation for reasonable values\n",
    "\n",
    "# Load data for analysis; only read if needed because the import can take a long time\n",
    "try:\n",
    "    if len(df.index) < 1:\n",
    "        df_raw = pd.read_csv(DATA_SOURCE) # If we get here, the dataframe was empty\n",
    "except:   \n",
    "    df_raw = pd.read_csv(DATA_SOURCE) # If we get here, the dataframe did not exist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 1,326,626 rows and 17 columns\n"
     ]
    }
   ],
   "source": [
    "df = df_raw\n",
    "print(\"The dataset has {:,} rows and {:,} columns\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Section_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleansing (Lab 1)\n",
    "\n",
    "The data cleansing steps performed below are repeated from Lab 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1278805 entries, 0 to 1326625\n",
      "Data columns (total 12 columns):\n",
      "Area ID               1278805 non-null object\n",
      "Reporting District    1278805 non-null object\n",
      "Age                   1278805 non-null int8\n",
      "Sex Code              1278805 non-null object\n",
      "Descent Code          1278805 non-null object\n",
      "Charge Group Code     1278805 non-null object\n",
      "Arrest Type Code      1278805 non-null object\n",
      "Location              1278805 non-null object\n",
      "Hour                  1278805 non-null object\n",
      "arrest_year           1278805 non-null object\n",
      "arrest_month          1278805 non-null object\n",
      "arrest_day_of_week    1278805 non-null object\n",
      "dtypes: int8(1), object(11)\n",
      "memory usage: 118.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Time - filter out 0 and missing\n",
    "df = df[df['Time'] != 0]\n",
    "df['Time'] = df['Time'].astype(str) \n",
    "df = df[df['Time'] != 'nan']\n",
    "\n",
    "# Time - Convert float to string. Get rid of decimals. Replace missing or invalid values with '0000'.\n",
    "df['Time'] = df['Time'].astype(str).str.split(\".\", expand = True)[0].replace(to_replace = ['2400','nan'], value = '0000') \n",
    "\n",
    "# Time - Fill time column with leading zeros to have 4 characters total\n",
    "df['Time'] = df['Time'].apply(lambda x: '{0:0>4}'.format(x))\n",
    "\n",
    "# Time - Add colon to Time values by converting attribute to a datetime variable \n",
    "df['Time'] = pd.to_datetime(df['Time'], format = '%H%M').dt.time\n",
    "\n",
    "# Age - Drop the observations where Age is less than 16\n",
    "df.drop(df[df['Age'] < 16].index, inplace = True) \n",
    "\n",
    "# Arrest Type Code - Drop the observations where Arrest Type Code = 'D'\n",
    "df.drop(df[df['Arrest Type Code'] == 'D'].index, inplace = True) \n",
    "\n",
    "# Descent Code - Re-classify any descent not in (B,H,O,W) into 0\n",
    "descent_list = ['B','H','O','W']\n",
    "df['Descent Code'] = np.where(np.isin(df['Descent Code'],descent_list),df['Descent Code'],'O')\n",
    "\n",
    "# Get hour\n",
    "df['Hour'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "# Convert Arrest Date to datetime\n",
    "df['Arrest Date'] = pd.to_datetime(df['Arrest Date'])\n",
    "\n",
    "# Extract year, month, and day of week and add to dataframe as new attributes\n",
    "df['arrest_year']= df['Arrest Date'].dt.year\n",
    "df['arrest_month']= df['Arrest Date'].dt.month\n",
    "df['arrest_day_of_week'] = df['Arrest Date'].dt.weekday_name\n",
    "\n",
    "# remove unecessary columns\n",
    "df.drop(['Cross Street','Charge Description','Charge','Charge Group Description','Time',\n",
    "         'Arrest Date','Report ID','Address','Area Name'], axis=1, inplace=True)\n",
    "\n",
    "# Change data types\n",
    "df['Age'] = df['Age'].astype(np.int8)\n",
    "df['Reporting District'] = df['Reporting District'].astype(np.str)\n",
    "df['Area ID'] = df['Area ID'].astype(np.str)\n",
    "df['Charge Group Code'] = df['Charge Group Code'].astype(np.str)\n",
    "df['Hour'] = df['Hour'].astype(np.str)\n",
    "df['arrest_year'] = df['arrest_year'].astype(np.str)\n",
    "df['arrest_month'] = df['arrest_month'].astype(np.str)\n",
    "df['arrest_day_of_week'] = df['arrest_day_of_week'].astype(np.str)\n",
    "\n",
    "# print clean dataset\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The clean data set has 1,278,805 rows and 12 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"The clean data set has {:,} rows and {:,} columns\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Section_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create A Logistic Regression Model and a Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform a logistic regression, all categorical variables need to be dummy encoded. For example, if a variable has 3 different categories we need to split this out to 3 different variables. The code below does this for the categorical variables used in the model. The target variable `Arrest Type Code` is transformed to range from 0-3 instead of alphabetical letters representing the arrest type. Also, `Age` was bucketed into 10 year increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Arrest Type Code as Categorical\n",
    "cleanup_arrest = {\"Arrest Type Code\": {\"F\": 0, \"M\": 1, \"I\": 2, \"O\":3}}\n",
    "df.replace(cleanup_arrest,inplace=True)\n",
    "\n",
    "# Create buckets for Age\n",
    "df['age_range'] = pd.cut(df.Age,[16,25,35,45,55,65,75,1e6],4,labels=[0,1,2,3,4,5,6]) # this creates a new variable\n",
    "df['age_range'] = df.age_range.astype(np.int)\n",
    "\n",
    "# Perform one-hot encoding of the categorical data \"Descent Code\"\n",
    "tmp_df = pd.get_dummies(df['Descent Code'],prefix='Descent')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# Replace the current Sex atribute with something slightly more intuitive and readable\n",
    "df['IsMale'] = df['Sex Code']=='M' \n",
    "df.IsMale = df.IsMale.astype(np.int)\n",
    "\n",
    "# Perform one-hot encoding of the categorical data \"DOW\"\n",
    "tmp_df = pd.get_dummies(df['arrest_day_of_week'],prefix='DOW')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# Perform one-hot encoding of the categorical data \"DOW\"\n",
    "tmp_df = pd.get_dummies(df['Area ID'],prefix='Area')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "# Perform one-hot encoding of the categorical data \"DOW\"\n",
    "tmp_df = pd.get_dummies(df['Charge Group Code'],prefix='Charge')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After properly encoding all variables, we remove the original variables from the dataset. We also remove any variables that will not be used in this model. Information about the resulting dataframe is printed for verification and the first 5 records are printed out.\n",
    "\n",
    "Note that this is just a first pass at the model, other variables will be used in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1278805 entries, 0 to 1326625\n",
      "Data columns (total 64 columns):\n",
      "Arrest Type Code    1278805 non-null int64\n",
      "age_range           1278805 non-null int32\n",
      "Descent_B           1278805 non-null uint8\n",
      "Descent_H           1278805 non-null uint8\n",
      "Descent_O           1278805 non-null uint8\n",
      "Descent_W           1278805 non-null uint8\n",
      "IsMale              1278805 non-null int32\n",
      "DOW_Friday          1278805 non-null uint8\n",
      "DOW_Monday          1278805 non-null uint8\n",
      "DOW_Saturday        1278805 non-null uint8\n",
      "DOW_Sunday          1278805 non-null uint8\n",
      "DOW_Thursday        1278805 non-null uint8\n",
      "DOW_Tuesday         1278805 non-null uint8\n",
      "DOW_Wednesday       1278805 non-null uint8\n",
      "Area_1              1278805 non-null uint8\n",
      "Area_10             1278805 non-null uint8\n",
      "Area_11             1278805 non-null uint8\n",
      "Area_12             1278805 non-null uint8\n",
      "Area_13             1278805 non-null uint8\n",
      "Area_14             1278805 non-null uint8\n",
      "Area_15             1278805 non-null uint8\n",
      "Area_16             1278805 non-null uint8\n",
      "Area_17             1278805 non-null uint8\n",
      "Area_18             1278805 non-null uint8\n",
      "Area_19             1278805 non-null uint8\n",
      "Area_2              1278805 non-null uint8\n",
      "Area_20             1278805 non-null uint8\n",
      "Area_21             1278805 non-null uint8\n",
      "Area_3              1278805 non-null uint8\n",
      "Area_4              1278805 non-null uint8\n",
      "Area_5              1278805 non-null uint8\n",
      "Area_6              1278805 non-null uint8\n",
      "Area_7              1278805 non-null uint8\n",
      "Area_8              1278805 non-null uint8\n",
      "Area_9              1278805 non-null uint8\n",
      "Charge_1.0          1278805 non-null uint8\n",
      "Charge_10.0         1278805 non-null uint8\n",
      "Charge_11.0         1278805 non-null uint8\n",
      "Charge_12.0         1278805 non-null uint8\n",
      "Charge_13.0         1278805 non-null uint8\n",
      "Charge_14.0         1278805 non-null uint8\n",
      "Charge_15.0         1278805 non-null uint8\n",
      "Charge_16.0         1278805 non-null uint8\n",
      "Charge_17.0         1278805 non-null uint8\n",
      "Charge_18.0         1278805 non-null uint8\n",
      "Charge_19.0         1278805 non-null uint8\n",
      "Charge_2.0          1278805 non-null uint8\n",
      "Charge_20.0         1278805 non-null uint8\n",
      "Charge_21.0         1278805 non-null uint8\n",
      "Charge_22.0         1278805 non-null uint8\n",
      "Charge_23.0         1278805 non-null uint8\n",
      "Charge_24.0         1278805 non-null uint8\n",
      "Charge_25.0         1278805 non-null uint8\n",
      "Charge_27.0         1278805 non-null uint8\n",
      "Charge_29.0         1278805 non-null uint8\n",
      "Charge_3.0          1278805 non-null uint8\n",
      "Charge_4.0          1278805 non-null uint8\n",
      "Charge_5.0          1278805 non-null uint8\n",
      "Charge_6.0          1278805 non-null uint8\n",
      "Charge_7.0          1278805 non-null uint8\n",
      "Charge_8.0          1278805 non-null uint8\n",
      "Charge_9.0          1278805 non-null uint8\n",
      "Charge_99.0         1278805 non-null uint8\n",
      "Charge_nan          1278805 non-null uint8\n",
      "dtypes: int32(2), int64(1), uint8(61)\n",
      "memory usage: 103.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_logreg = df\n",
    "\n",
    "df.drop(['Sex Code','Descent Code','arrest_day_of_week','Area ID','Reporting District','Charge Group Code',\n",
    "         'Location','arrest_year','Age','Hour','arrest_month'], axis=1, inplace=True)\n",
    "    \n",
    "df_logreg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arrest Type Code</th>\n",
       "      <th>age_range</th>\n",
       "      <th>Descent_B</th>\n",
       "      <th>Descent_H</th>\n",
       "      <th>Descent_O</th>\n",
       "      <th>Descent_W</th>\n",
       "      <th>IsMale</th>\n",
       "      <th>DOW_Friday</th>\n",
       "      <th>DOW_Monday</th>\n",
       "      <th>DOW_Saturday</th>\n",
       "      <th>...</th>\n",
       "      <th>Charge_29.0</th>\n",
       "      <th>Charge_3.0</th>\n",
       "      <th>Charge_4.0</th>\n",
       "      <th>Charge_5.0</th>\n",
       "      <th>Charge_6.0</th>\n",
       "      <th>Charge_7.0</th>\n",
       "      <th>Charge_8.0</th>\n",
       "      <th>Charge_9.0</th>\n",
       "      <th>Charge_99.0</th>\n",
       "      <th>Charge_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Arrest Type Code  age_range  Descent_B  Descent_H  Descent_O  Descent_W  \\\n",
       "0                 1          0          1          0          0          0   \n",
       "1                 0          2          0          1          0          0   \n",
       "2                 0          0          0          1          0          0   \n",
       "3                 0          1          0          0          1          0   \n",
       "5                 0          2          0          0          0          1   \n",
       "\n",
       "   IsMale  DOW_Friday  DOW_Monday  DOW_Saturday  ...  Charge_29.0  Charge_3.0  \\\n",
       "0       0           1           0             0  ...            0           0   \n",
       "1       1           0           1             0  ...            0           1   \n",
       "2       0           0           0             1  ...            0           1   \n",
       "3       1           0           0             0  ...            0           0   \n",
       "5       1           0           0             0  ...            0           0   \n",
       "\n",
       "   Charge_4.0  Charge_5.0  Charge_6.0  Charge_7.0  Charge_8.0  Charge_9.0  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           1           0           0           0           0   \n",
       "5           1           0           0           0           0           0   \n",
       "\n",
       "   Charge_99.0  Charge_nan  \n",
       "0            0           1  \n",
       "1            0           0  \n",
       "2            0           0  \n",
       "3            0           0  \n",
       "5            0           0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section of code below sets up the frame for the logistic regression model. The target `Arrest Type Code` is identified and all other variables are assigned as explanatory variables.\n",
    "\n",
    "Also indicated in this section of code is the training/test split of 80%/20%. The model will be built with 80% of the data and tested on the remaining 20%.\n",
    "\n",
    "Note that only one iteration of the model is being run. This is due to the time is takes to run the model with the number of observations and variables we have in the dataset. In future assignments, we will run through more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training/test split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'Arrest Type Code' in df_logreg:\n",
    "    y = df_logreg['Arrest Type Code'].values # get the labels we want\n",
    "    del df_logreg['Arrest Type Code'] # get rid of the class label\n",
    "    X = df_logreg.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 1\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below splits the data into the training/test split identified earlier and runs a multi-nomial logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(multi_class='multinomial', solver='newton-cg' ) # get object\n",
    "\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    lr_clf.fit(X[train_indices],y[train_indices])  # train object\n",
    "    y_hat = lr_clf.predict(X[test_indices]) # get test set precitions\n",
    "\n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", mt.accuracy_score(y[test_indices],y_hat)) \n",
    "    print(\"confusion matrix\\n\",mt.confusion_matrix(y[test_indices],y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for this iteration of the model is 75.9%. Without adjusting model parameters, we are already very close to our target accuracy of 75%. The various iterations we have run ranged from accuracy of 70% to 78%.\n",
    "\n",
    "It is interesting to note that the model never predicts the arrest type codes I-Infraction and O-Other. In future iterations, we will try to improve this, but it may be difficult due to the limited number of observations available for the arrest types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
